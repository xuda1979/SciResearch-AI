\documentclass{article}
\title{Idea 10: Knowledge Fossilization via Micro-Theorems}
\author{}
\date{}
\begin{document}
\maketitle

\section{Introduction}
Large language models are prone to forgetting or misrepresenting
established facts when updated or fine-tuned. To counteract this
drift, we propose knowledge fossilization via micro-theorems. Each
important domain fact is formalized as a small theorem with an
accompanying test or proof. During generation, these micro-theorems
can be referenced or imported, ensuring that critical relationships
remain consistent across model updates.

\section{Method}
A micro-theorem captures a factual relationship (e.g., ``ICD--10 code
X corresponds to condition Y'') and includes a short proof or
verification function. By organizing the knowledge base into such
units, we can enforce that any output using these facts must pass the
associated tests. Micro-theorems can be versioned and expired when the
underlying fact changes.

\section{Implementation}
To implement this idea, we build a library of micro-theorems as Python
modules with unit tests. The language model is restricted to import
from this library when generating answers in regulated domains. A
constrained decoding mechanism ensures that references to domain
knowledge call the corresponding micro-theorem functions. If a
generated statement fails its test, the model revises the statement or
abstains. The accompanying \texttt{code.py} file demonstrates this
concept and imports the \texttt{sciresearch\_ai} package for version
information.

\end{document}